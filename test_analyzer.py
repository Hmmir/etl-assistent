#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ETL Assistant

–ú–æ–¥—É–ª—å 4: –†–∞–±–æ—Ç–∞ —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CSV –∞–Ω–∞–ª–∏–∑–∞
"""

import sys
import os
sys.path.append('backend')

from data_analyzers import DataAnalyzer, StorageRecommendationEngine
import json

def test_analyzer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ"""
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    analyzer = DataAnalyzer()
    recommender = StorageRecommendationEngine()
    
    # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É
    test_file = "backend/uploads/museum_data_sample.csv"
    
    if not os.path.exists(test_file):
        print(f"‚ùå –§–∞–π–ª {test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    print("üîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
    print(f"üìÅ –§–∞–π–ª: {test_file}")
    
    try:
        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
        print("\nüìä –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")
        analysis = analyzer.analyze_file(test_file)
        
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω:")
        print(f"   üìÑ –§–æ—Ä–º–∞—Ç: {analysis.get('format_type')}")
        print(f"   üìè –†–∞–∑–º–µ—Ä: {analysis.get('file_size_mb')} MB")
        print(f"   üìã –°—Ç—Ä–æ–∫: {analysis.get('total_rows', 'N/A'):,}")
        print(f"   üìä –ö–æ–ª–æ–Ω–æ–∫: {analysis.get('total_columns', 'N/A')}")
        print(f"   üóÇÔ∏è –ö–æ–¥–∏—Ä–æ–≤–∫–∞: {analysis.get('encoding')}")
        print(f"   üîó –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{analysis.get('separator')}'")
        print(f"   üìà –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö: {analysis.get('estimated_data_volume')}")
        
        print("\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–ª–æ–Ω–æ–∫:")
        for i, col in enumerate(analysis.get('columns', [])[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            null_pct = col.get('null_percentage', 0)
            print(f"   {i:2d}. {col['name']:25s} | {col['data_type']:10s} | Null: {null_pct:5.1f}% | –ü—Ä–∏–º–µ—Ä—ã: {col.get('sample_values', [])[:2]}")
        
        if len(analysis.get('columns', [])) > 10:
            print(f"   ... –∏ –µ—â–µ {len(analysis.get('columns', [])) - 10} –∫–æ–ª–æ–Ω–æ–∫")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        print("\nüéØ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ö—Ä–∞–Ω–∏–ª–∏—â—É...")
        recommendation = recommender.recommend_storage(analysis)
        
        print("\nüèóÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   üóÑÔ∏è –•—Ä–∞–Ω–∏–ª–∏—â–µ: {recommendation['recommended_storage']}")
        print(f"   üí° –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {recommendation['reasoning']}")
        
        print("\nüìù DDL –°–∫—Ä–∏–ø—Ç:")
        print("‚îÄ" * 80)
        print(recommendation['ddl_script'])
        print("‚îÄ" * 80)
        
        print("\nüîß –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
        for i, opt in enumerate(recommendation['optimization_suggestions'], 1):
            print(f"   {i}. {opt}")
        
        print("\nüéâ –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
        # –°–æ—Ö—Ä–∞–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        with open('analysis_result.json', 'w', encoding='utf-8') as f:
            json.dump({
                'analysis': analysis,
                'recommendation': recommendation
            }, f, ensure_ascii=False, indent=2)
        print("\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ analysis_result.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_analyzer()
